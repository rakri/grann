{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hnswlib\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import requests\n",
    "import tempfile\n",
    "import time\n",
    "import struct\n",
    "import itertools\n",
    "\n",
    "from core_utils import read_float_binary_file,read_i8_binary_file,read_u8_binary_file,write_float_binary_file,read_int32_binary_file,compute_recall,get_bin_metadata,omp_sum_of_squares\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queries,gt, and base metadata loaded\n"
     ]
    }
   ],
   "source": [
    "query_file = '/home/rakri/wiki_rnd1m/wikipedia_query.bin'\n",
    "gt_file = '/home/rakri/wikipedia_gt_unfilt.bin'\n",
    "base_file = '/home/rakri/wikipedia/mem_r64_l100.data'\n",
    "dataset_name='wiki_large'\n",
    "\n",
    "#gt_file = '/home/rakri/wiki_rnd1m_gt100.bin'\n",
    "#base_file = '/home/rakri/wiki_rnd1m_data.bin'\n",
    "#dataset_name='wiki_rnd1m'\n",
    "\n",
    "\n",
    "[nqgt, nkgt, gt] = read_int32_binary_file(gt_file)\n",
    "[nq, ndq, queries] = read_float_binary_file(query_file)\n",
    "[nb, nd] = get_bin_metadata(base_file)\n",
    "\n",
    "print (\"queries,gt, and base metadata loaded\")\n",
    "\n",
    "#names and parameters\n",
    "Mb = 16\n",
    "efb = 200\n",
    "index_name = '/home/rakri/hnsw_'+dataset_name+'M='+str(Mb)+'_efC='+str(efb) \n",
    "\n",
    "# for hnsw, it is only ef_search\n",
    "search_params = [(10), (20), (30), (40), (50), (60), (70), (80), (90), (100), (150), (200), (250), (300)]\n",
    "\n",
    "\n",
    "# Create a NumPy array.\n",
    "A = np.array([[1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3], [4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6], [7, 8, 9, 7, 8, 9, 7, 8, 9, 7, 8, 9]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "[nb, nd, dataset] = read_float_binary_file(base_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arr = np.array([[1, 2, 3], [4, 5, 6], [1, 2, 3]])\n",
    "#row_sums = np.sum(dataset, axis=1)\n",
    "#row_sums = np.sum(dataset ** 2, axis=1)\n",
    "row_sums = omp_sum_of_squares(dataset)\n",
    "print(row_sums.shape)\n",
    "# Create an array\n",
    "#arr = np.array([1, 2, 3, 1, 4, 5, 2, 5])\n",
    "\n",
    "# Get the unique values\n",
    "unique_elements = np.unique(row_sums)\n",
    "\n",
    "# Print the unique values\n",
    "print(unique_elements.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index exists, so loading\n"
     ]
    }
   ],
   "source": [
    "# Create an HNSW index\n",
    "index = hnswlib.Index(space='l2', dim=nd)\n",
    "\n",
    "index.init_index(max_elements=nb, M = Mb, ef_construction = efb, random_seed = 100)\n",
    "\n",
    "print (\"index initialized\")\n",
    "if os.path.isfile(index_name):\n",
    "    print(\"Index exists, so loading\")\n",
    "    index = hnswlib.Index(space='l2', dim=nd)\n",
    "    index.load_index(index_name, max_elements = nb)\n",
    "else:\n",
    "    #index.set_num_threads()\n",
    "    start = time.time()\n",
    "    [nb, nd, dataset] = read_float_binary_file(base_file)\n",
    "    index.add_items(dataset)\n",
    "    end = time.time()\n",
    "    print(\"Index built in\", end-start, \" seconds.\")\n",
    "    index.save_index(index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ef\tRecall\t\ttime\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 \t 0.68444 \t 61.86943054199219\n",
      "20 \t 0.73324 \t 114.05119895935059\n",
      "30 \t 0.82468 \t 162.32924461364746\n",
      "40 \t 0.88636 \t 207.39431381225586\n",
      "50 \t 0.9136 \t 247.88260459899902\n",
      "60 \t 0.93184 \t 286.47656440734863\n",
      "70 \t 0.95938 \t 324.2431640625\n",
      "80 \t 0.98924 \t 362.2021198272705\n",
      "90 \t 0.99904 \t 401.24807357788086\n",
      "100 \t 0.99988 \t 439.23306465148926\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Search for the nearest neighbor of a query vector\n",
    "\n",
    "index.set_num_threads(1)\n",
    "nk=10\n",
    "print(\"ef\\tRecall\\t\\ttime\")\n",
    "for param in search_params:\n",
    "    (ef_search) = param\n",
    "    index.set_ef(ef_search)\n",
    "    start = time.time()\n",
    "    neighbors, distances = index.knn_query(queries, k=nk)\n",
    "    end = time.time()\n",
    "    recall = compute_recall(neighbors, gt[:,:nk])\n",
    "    print(ef_search,\"\\t\",recall,\"\\t\",1000000*(end-start)/nq)\n",
    "# Print the nearest neighbor\n",
    "#print(neighbors)\n",
    "#print(distances)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
